How to drop rows of Pandas DataFrame whose value in certain columns is NaN
I have a ` DataFrame ` :
Then I just want the records whose ` EPS ` is not ` NaN ` , that is , ` df.drop ( .... )` will return the dataframe as below :
How do I do that ?
dropna : pandas.pydata.org/pandas-docs/stable/generated
` df.dropna ( subset = [ ' column1_name ' , ' column2_name ' , ' column3_name '])`
Don't ` drop ` . Just take rows where ` EPS ` is finite :
I'd recommend using ` pandas.notnull ` instead of ` np.isfinite `
@USER The docs say that pandas.notnull is a direct replacement for np.isfinite . In this case , null does not mean zero .
Is there any advantage to indexing and copying over dropping ?
Creates Error : TypeError : ufunc ' isfinite ' not supported for the input types , and the inputs could not be safely coerced to any supported types according to the casting rule '' safe ''
This question is already resolved , but ...
... also consider the solution suggested by Wouter in his original comment . The ability to handle missing data , including ` dropna() ` , is built into pandas explicitly . Aside from potentially improved performance over doing it manually , these functions also come with a variety of options which may be useful .
There are also other options ( See docs at http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.dropna.html ) , including dropping columns instead of rows .
Pretty handy !
you can also use ` df.dropna ( subset = [ ' column_name '])` . Hope that saves at least one person the extra 5 seconds of ' what am I doing wrong ' . Great answer , +1
@USER , I just spent 20 minutes to write a function for that ! The official documentation was very cryptic : " Labels along other axis to consider , e.g. if you are dropping rows these would be a list of columns to include " . I was unable to understand , what they meant ...
I know this has already been answered , but just for the sake of a purely pandas solution to this specific question as opposed to the general description from Aman ( which was wonderful ) and in case anyone else happens upon this :
Actually , the specific answer would be : ` df.dropna ( subset =[ ' EPS '])` ( based on the general description of Aman , of course this does also work )
` notnull ` is also what Wes ( author of Pandas ) suggested in his comment on another answer .
This maybe a noob question . But when I do a df [ pd.notnull ( ... ) or df.dropna the index gets dropped . So if there was a null value in row-index 10 in a df of length 200 . The dataframe after running the drop function has index values from 1 to 9 and then 11 to 200 . Anyway to " re-index " it
You could use dataframe method notnull or inverse of isnull , or numpy.isnan :
notnull is very nice !
yet another solution which uses the fact that ` np.nan ! = np.nan ` :
You can use this :
It may be added at that ' ' can be used to add additional conditions e.g .
Notice that when evaluating the statements , pandas needs parenthesis .
Sorry , but OP want someting else . Btw , your code is wrong , return ` ValueError : The truth value of a Series is ambiguous . Use a.empty , a.bool() , a.item() , a.any() or a.all() . ` . You need add parenthesis - ` df = df [( df.EPS 2.0 ) ( df.EPS 4.0 )]` , but also it is not answer for this question .
For some reason none of the previously submitted answers worked for me . This basic solution did :
Though of course that will drop rows with negative numbers , too . So if you want those it's probably smart to add this after , too .