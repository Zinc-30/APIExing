Select rows from a DataFrame based on values in a column in pandas
How to select rows from a DataFrame based on values in some column in pandas ?
In SQL I would use :
I tried to look at pandas documentation but did not immediately find the answer .
To select rows whose column value equals a scalar , ` some_value ` , use ` == ` :
To select rows whose column value is in an iterable , ` some_values ` , use ` isin ` :
Combine multiple conditions with ` ` :
To select rows whose column value does not equal ` some_value ` , use ` ! = ` :
` isin ` returns a boolean Series , so to select rows whose value is not in ` some_values ` , negate the boolean Series using ` ~ ` :
For example ,
yields
If you have multiple values you want to include , put them in a
list ( or more generally , any iterable ) and use ` isin ` :
yields
Note , however , that if you wish to do this many times , it is more efficient to
make an index first , and then use ` df.loc ` :
yields
or , to include multiple values from the index use ` df.index.isin ` :
yields
In fact , df [ df [ ' colume_name '] == some_value ] also works . But my first attempt , df.where ( df [ ' colume_name '] == some_value ) does not work ... not sure why ...
When you use ` df.where ( condition )` , the condition has to have the same shape as ` df ` .
Those links could be very useful to many of you : pandas.pydata.org/pandas-docs/stable/indexing.html gregreda.com/2013/10/26/working-with-pandas-dataframes
FYI : If you want to select a row based upon two ( or more ) labels ( either requiring both or either ) , see stackoverflow.com/questions/31756340
What about the negative " isnotin " does that exist ?
tl ;d r
The pandas equivalent to
is
Multiple conditions :
or
Code example
In the above code it is the line ` df [ df.foo == 222 ]` that gives the rows based on the column value , ` 222 ` in this case .
Multiple conditions are also possible :
But at that point I would recommend using the query function , since it's less verbose and yields the same result :
This is great for 1 condition , but what if you have 2 conditions ? For example , you also have column_name2 == some_value2 ?
` table [( table.column_name == some_value ) | ( table.column_name2 == some_value2 ) ]` would do the trick . But at that point I would probably use the query-function fredcallaway mentions . I will update my answer to include this information .
I find the syntax of the previous answers to be redundant and difficult to remember . Pandas introduced the ` query() ` method in v0.13 and I much prefer it . For your question , you could do ` df.query ( ' col == val ')`
Reproduced from http://pandas.pydata.org/pandas-docs/version/0.17.0/indexing.html#indexing-query
You can also access variables in the environment by prepending an ` @ ` .
You only need package ` numexpr ` installed .
In my case I needed quotation because val is a string . df.query ( ' col == " val "')
Here is a simple example
I just tried editing this , but I wasn't logged in , so I'm not sure where my edit went . I was trying to incorporate multiple selection . So I think a better answer is :
For a single value , the most straightforward ( human readable ) is probably :
For lists of values you can also use :
For example ,
yields
If you have multiple criteria you want to select against , you can put them in a list and use ' isin ' :
yields
Note , however , that if you wish to do this many times , it is more efficient to make A the index first , and then use df.loc :
yields
How is this any different from imolit's answer ?
If you came here looking to select rows from a dataframe by including those whose column's value is NOT any of a list of values , here's how to flip around unutbu's answer for a list of values above :
( To not include a single value , of course , you just use the regular not equals operator , ` ! = ` . )
Example :
gives us
To subset to just those rows that AREN'T ` one ` or ` three ` in column ` B ` :
yields
To append to this famous question ( though a bit too late ): You can also do ` df.groupby ( ' column_name ') .get_group ( ' column_desired_value ') .reset_index() ` to make a new data frame with specified column having a particular value . E.g .
Run this gives :
Using numpy.where results can be achieved faster ,
using unubtu setup :