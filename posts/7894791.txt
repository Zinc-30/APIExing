Use numpy array in shared memory for multiprocessing
I would like to use a numpy array in shared memory for use with the multiprocessing module . The difficulty is using it like a numpy array , and not just as a ctypes array .
This produces output such as :
The array can be accessed in a ctypes manner , e.g. a [ i ] makes sense . However , it
is not a numpy array , and I cannot perform operations such as -1*a , or a.sum() . I suppose a solution would be to convert the ctypes array into a numpy array . However ( besides not being able to make this work ) , I don't believe it would be shared anymore .
It seems there would be a standard solution to what has to be a common problem .
It's not the same as this one ? stackoverflow.com/questions/5033799
It's not quite the same question . The linked question is asking about ` subprocess ` rather than ` multiprocessing ` .
To add to @USER ' s ( not available anymore ) and @USER Gomersall's answers . You could use ` shared_arr.get_lock() ` to synchronize access when needed :
Example
If you don't need synchronized access or you create your own locks then ` mp.Array() ` is unnecessary . You could use ` mp.sharedctypes.RawArray ` in this case .
Beautiful answer ! If I want to have more than one shared array , each separately lockable , but with the number of arrays determined at runtime , is that a straightforward extension of what you've done here ?
@USER : shared arrays should be created before child processes are spawned .
Good point about order of operations . That's what I had in mind , though : create a user-specified number of shared arrays , then spawn a few child processes . Is that straightforward ?
I've made another question to deal with this detail : stackoverflow.com/q/14416130/513688
@USER : you can't change the size of the Array . Think of it as a shared block of memory that had to be allocated before child processes are started . You don't need to use all the memory e.g. , you could pass ` count ` to ` numpy.frombuffer() ` . You could try to do it on a lower level using ` mmap ` or something like ` posix_ipc ` directly to implement a resizable ( might involve copying while resizing ) RawArray analog ( or look for an existing library ) . Or if your task allows it : copy data in parts ( if you don't need all at once ) . " How to resize a shared memory " is a good separate question .
The ` Array ` object has a ` get_obj() ` method associated with it , which returns the ctypes array which presents a buffer interface . I think the following should work ...
When run , this prints out the first element of ` a ` now being 10.0 , showing ` a ` and ` b ` are just two views into the same memory .
In order to make sure it is still multiprocessor safe , I believe you will have to use the ` acquire ` and ` release ` methods that exist on the ` Array ` object , ` a ` , and its built in lock to make sure its all safely accessed ( though I'm not an expert on the multiprocessor module ) .
it won't work without synchronization as @USER demonstrated in his ( now deleted ) answer .
Presumably , if you just wanted to access the array post processing , it can be done cleanly without worrying about concurrency issues and locking ?
in this case you don't need ` mp.Array ` .
The processing code may require locked arrays , but the post processing interpretation of the data might not necessarily . I guess this comes from understanding what exactly the problem is . Clearly , accessing shared data concurrently is going to require some protection , which I thought would be obvious !
You can use the ` sharedmem ` module : https://bitbucket.org/cleemesser/numpy-sharedmem
Here's your original code then , this time using shared memory that behaves like a NumPy array ( note the additional last statement calling a NumPy ` sum() ` function ):
Note : this is no longer being developed and does not seem to work on linux github.com/sturlamolden/sharedmem-numpy/issues/4
numpy-sharedmem may not be in development , but it still works on Linux , check out github.com/vmlaker/benchmark-sharedmem .
I've written a small python module that uses POSIX shared memory to share numpy arrays between python interpreters . Maybe you will find it handy .
https://pypi.python.org/pypi/SharedArray
Here's how it works :
While the answers already given are good , there is a much easier solution to this problem provided two conditions are met :
You are on a POSIX-compliant operating system ( e.g. Linux , Mac OSX ); and
Your child processes need read-only access to the shared array .
In this case you do not need to fiddle with explicitly making variables shared , as the child processes will be created using a fork . A forked child automatically shares the parent's memory space . In the context of Python multiprocessing , this means it shares all module-level variables ; note that this does not hold for arguments that you explicitly pass to your child processes or to the functions you call on a ` multiprocessing.Pool ` or so .
A simple example :