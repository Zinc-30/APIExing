Pandas DataFrame iloc spoils the data type
Having pandas 0.19.2 .
Here's an example :
Output :
Everything looks fine for now , but what I don't like is that ( note , that first call is a ` pd.Series.iloc ` and the second one is ` pd.DataFrame.iloc `)
Output :
I found it while trying to understand why ` pd.DataFrame.join() ` operation returned almost no intersections of two ` int64 ` columns while there should be many .
My guess is because of type inconsistency which might be connected with this behaviour , but I'm not sure ... My short investigation revealed the thing above and now I'm confused a bit .
If someone knows how to solve it - I'll be very grateful for any hints !
UPD
Thanks to @USER for comments . So here is the example with my generated data and join / merge behaviour
` testdf.join ( testdf , on= ' A ' , rsuffix= ' 3 ')`
And what is considered to be quite the same
` pd.merge ( left=testdf , right=testdf , on= ' A ')`
returns
UPD2 Replicating @USER comment on ` join ` and ` merge ` behaviour . The problem is that ` A.join ( B , on= ' C ')` will use index in ` A ` and join it with column ` B [ ' C ']` , since by default join uses index . In my case I just used merge to get desireable result .
` iloc ` returns a series of your row , there is no dtype that will satisfy both int and float hence ` object ` is shown , what's the problem here as your row is a mixed dtype ?
if your columns you're trying to match are int64 then value comparison should work as expected , if they're float then this may run into precision problems , this has nothing to do with what you're showing above
@USER Well , thanks , your point explains my example . My columns are not float , so this is a problem somewhere . For example , I can manually find specified value in both tables , however , join fails for it .
It sounds like you have a data problem , if your values don't match exactly then they won't join / merge you need to solve that issue first . try ` merge ` and pass a list of columns to ` on= ` , if have missing values in a column then the dtype becomes float , additionally trying to merge ` NaN ` will introduce errors , you need to decide whether to replace these or drop them but I can't tell without seeing your data and code of your real problem
note ` join ` by default tries to join on index , ` merge ` will try to merge on columns , they are semantically different but you can get the same results depending on params passed
This is as expected . ` pandas ` tracks ` dtypes ` per column . When you call ` testdf.iloc [ 0 ]` you are asking pandas for a row . It has to convert the entire row into a series . That row contained a float . Therefore the row as a series must be float .
However , it seems that when pandas uses ` loc ` or ` iloc ` it makes this conversion when you use a single ` __getitem__ `
Here are some interesting test cases for a ` testdf ` with one ` int ` column
Change it to OP test case
So , it appears that when ` pandas ` uses ` loc ` or ` iloc ` it makes some conversions across rows which I still don't fully understand . I'm sure it has something to do with the fact that the nature of ` loc ` and ` iloc ` are different than ` at ` , ` iat ` , ` get_value ` in that ` iloc ` and ` loc ` allow you to access the dataframe with index arrays and boolean arrays . While ` at ` , ` iat ` , and ` get_value ` only access a single cell at a time .
Despite that
When we assign to that location via ` loc ` , ` pandas ` ensures the ` dtype ` stays consistent .
Thank you for a very detailed explanation !