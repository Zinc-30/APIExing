Pandas	O
GroupBy	B-API
memory	O
deallocation	O

Problem	O

I	O
noticed	O
that	O
memory	O
allocated	O
while	O
iterating	O
through	O
a	O
Pandas	O
GroupBy	B-API
object	O
is	O
not	O
deallocated	O
after	O
iteration	O
.	O

I	O
use	O
`	O
resource.getrusage	O
(	O
resource.RUSAGE_SELF	O
)	O
.ru_maxrss	O
`	O
(	O
second	O
answer	O
in	O
this	O
post	O
for	O
details	O
)	O
to	O
measure	O
the	O
total	O
amount	O
of	O
active	O
memory	O
used	O
by	O
the	O
Python	O
process	O
.	O

prints	O
the	O
following	O
total	O
active	O
memory	O
(	O
in	O
gb	O
)	O

Solutions	O

Uncommenting	O
`	O
del	O
idx	O
,	O
x	O
`	O
and	O
`	O
gc.collect()	O
`	O
fixes	O
the	O
problem	O
.	O

I	O
do	O
however	O
have	O
to	O
`	O
del	O
`	O
all	O
variables	O
that	O
reference	O
the	O
DataFrames	O
returned	O
by	O
iterating	O
over	O
the	O
groupby	B-API
(	O
which	O
can	O
be	O
a	O
pain	O
depending	O
on	O
the	O
code	O
in	O
the	O
inner	O
for	O
loop	O
)	O
.	O

The	O
new	O
printed	O
memory	O
usages	O
become	O
:	O

Alternatively	O
I	O
can	O
uncomment	O
`	O
gb	O
=	O
list	O
(	O
gb	O
)`	O
.	O

The	O
resulting	O
memory	O
usages	O
are	O
roughly	O
the	O
same	O
as	O
those	O
from	O
the	O
previous	O
solution	O
:	O

Questions	O

Why	O
is	O
memory	O
for	O
DataFrames	O
resulting	O
from	O
iteration	O
through	O
the	O
groupby	B-API
not	O
deallocated	O
after	O
iteration	O
is	O
completed	O
?	O

Is	O
there	O
a	O
better	O
solution	O
than	O
the	O
two	O
above	O
?	O

If	O
not	O
,	O
which	O
of	O
these	O
two	O
solutions	O
is	O
"	O
better	O
"	O
?	O

Are	O
you	O
using	O
python2	O
or	O
3	O
?	O

Using	O
Python3.4	O

It	O
is	O
strange	O
,	O
there	O
are	O
new	O
objects	O
created	O
on	O
each	O
iteration	O
and	O
somehow	O
there	O
is	O
a	O
reference	O
being	O
kept	O
so	O
just	O
calling	O
gc.collect	O
is	O
not	O
enough	O
.	O

Using	O
the	O
list	O
approach	O
the	O
same	O
objects	O
are	O
reused	O
so	O
you	O
see	O
no	O
increase	O
in	O
memeory	O
.	O

Memory	O
Weirdness	O

This	O
is	O
very	O
interesting	O
!	O

You	O
do	O
not	O
need	O
`	O
del	O
idx	O
,	O
x	O
`	O
.	O

Only	O
using	O
`	O
gc.collect()	O
`	O
worked	O
to	O
keep	O
memory	O
constant	O
for	O
me	O
.	O

This	O
is	O
much	O
cleaner	O
that	O
having	O
the	O
`	O
del	O
`	O
statements	O
inside	O
the	O
loop	O
.	O

I	O
do	O
not	O
get	O
the	O
same	O
results	O
.	O

If	O
I	O
don't	O
`	O
del	O
`	O
the	O
reference	O
`	O
x	O
`	O
then	O
memory	O
increases	O
twice	O
(	O
~	O
0.67gb	O
-	O
~	O
1.3gb	O
-	O
2gb	O
)	O
.	O

Hmm	O
...	O

I	O
ran	O
this	O
in	O
iPython	O
and	O
`	O
del	O
`	O
was	O
not	O
needed	O
...	O
what	O
are	O
you	O
running	O
this	O
in	O
?	O

You	O
mean	O
what	O
version	O
of	O
Pandas	O
?	O

0.18.0	O

What	O
environment	O
?	O

Inside	O
iPython	O
?	O

Command	O
line	O
?	O

Part	O
of	O
another	O
full	O
application	O
?	O

Why	O
is	O
memory	O
for	O
DataFrames	O
resulting	O
from	O
iteration	O
through	O
the	O
groupby	B-API
not	O
deallocated	O
after	O
iteration	O
is	O
completed	O
?	O

Nowhere	O
in	O
your	O
code	O
you	O
`	O
del	O
`	O
object	O
`	O
gb	O
`	O
,	O
which	O
means	O
at	O
the	O
end	O
it's	O
still	O
there	O
.	O

One	O
thing	O
is	O
to	O
have	O
an	O
iterator	O
reach	O
the	O
end	O
of	O
its	O
cycle	O
,	O
then	O
I	O
would	O
expect	O
it	O
to	O
die	O
automagically	O
,	O
but	O
the	O
object	O
that	O
gave	O
rise	O
to	O
the	O
iterator	O
persists	O
,	O
in	O
case	O
you	O
need	O
to	O
do	O
something	O
else	O
(	O
iterate	O
again	O
,	O
aggregate	B-API
,	O
etc	O
)	O
.	O

o.o	O
wutizusaying	O

